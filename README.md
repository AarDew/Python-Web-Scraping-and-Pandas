# Web Scraping Real-World Data using Python & Pandas

## ğŸ“Œ Project Overview
This project focuses on scraping real-world data from Wikipedia using Python.
The data was extracted using the `requests` and `BeautifulSoup` libraries,
processed, and stored in a structured format using Pandas.

This project involved understanding HTML structure, handling inconsistencies
during scraping, and converting unstructured web data into a usable dataset.

## ğŸŒ Data Source
- Wikipedia (real public web data)

## ğŸ›  Tools & Libraries Used
- Python
- BeautifulSoup (bs4)
- Requests
- Pandas
- Jupyter Notebook

## ğŸ” Project Workflow
1. Sent HTTP requests to fetch webpage content
2. Parsed HTML using BeautifulSoup
3. Used `find()` and `find_all()` to extract relevant data
4. Cleaned and structured the scraped data
5. Stored the data into a CSV file
6. Performed basic data handling using Pandas

## âš ï¸ Challenges Faced
- Understanding HTML tags and structure
- Handling missing or inconsistent data
- Debugging incorrect selectors
- Managing data extraction logic

## ğŸ“ˆ Outcome
- Successfully scraped real data from Wikipedia
- Converted unstructured data into a structured dataset
- Built a strong foundation for future Pandas-based analysis

## ğŸ¯ Learning Outcome
- Practical experience with web scraping
- Improved problem-solving and debugging skills
- Hands-on exposure to real-world data collection
